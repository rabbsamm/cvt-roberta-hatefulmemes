{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2482bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, CvtForImageClassification, AutoTokenizer, RobertaModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from string import digits\n",
    "from html import unescape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchmetrics.functional.classification import auroc, accuracy\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from lightning.pytorch import seed_everything\n",
    "import lightning.pytorch as lp\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e70c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## os.chdir(r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = {\n",
    "    'vmodel_name': 'microsoft/cvt-21',\n",
    "    'vmodel_path': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models\\Finetuned_CvT_589.pth.tar',\n",
    "    'tmodel_name': 'roberta-base',\n",
    "    'tmodel_path': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models\\Finetuned_Roberta_Lou.pth.tar',\n",
    "    'n_labels': 2,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.492,\n",
    "    'w_decay': 0.032,\n",
    "    'lr': 5e-5,\n",
    "    'hidden_size': 128,\n",
    "    'n_epochs': 15,\n",
    "    'device': device,\n",
    "    'n_img_train': 1,\n",
    "    'n_img_val': 1,\n",
    "    'n_img_test': 1000,\n",
    "    'img_train': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\img_preprocessed',\n",
    "    'img_val': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\img_preprocessed',\n",
    "    'img_test': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\img_preprocessed',\n",
    "    'label_train':r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\train.jsonl',\n",
    "    'label_val': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\dev_seen.jsonl',\n",
    "    'label_test': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\test_seen.jsonl',\n",
    "    'reload': False,\n",
    "    'img_train_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\img_train.pt',\n",
    "    'img_val_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\img_val.pt',\n",
    "    'img_test_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\img_test.pt',\n",
    "    'text_train_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\text_train.pkl',\n",
    "    'text_val_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\text_val.pkl',\n",
    "    'text_test_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\text_test.pkl',\n",
    "    'label_train_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\labels_train.pkl',\n",
    "    'label_val_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\labels_val.pkl',\n",
    "    'label_test_rl': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Data\\hateful_memes\\labels_test.pkl',\n",
    "    'seed': 24,\n",
    "    'ckpt_path': r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models',\n",
    "    'val_every': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccac0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Load_Memes(config):\n",
    "    #Load Extractor\n",
    "    extractor = AutoFeatureExtractor.from_pretrained(config['vmodel_name'])\n",
    "    #Load Train Data\n",
    "    n = 0\n",
    "    label_train = pd.read_json(config['label_train'], lines = True, nrows = config['n_img_train'])\n",
    "    img_train_id = list(label_train['id'].values)\n",
    "    img_train_list = [config['img_train'] + r'\\\\' + str(i).zfill(5) + '.png' for i in img_train_id]\n",
    "    for img_path in img_train_list:\n",
    "        if n == 0:\n",
    "            img_train = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
    "            print('Training Image', str(n), 'loaded.')\n",
    "        else:\n",
    "            img_train = torch.cat((img_train.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n",
    "        n += 1\n",
    "        if (n % 1000 == 0):\n",
    "            print('Training Image', str(n), 'loaded.')\n",
    "    \n",
    "    text_train = list(label_train['text'].values)\n",
    "    print('Training Text', str(config['n_img_train']), 'loaded.')\n",
    "    \n",
    "    labels_train = list(label_train['label'].values)\n",
    "    print('Training Label', str(config['n_img_train']), 'loaded.')\n",
    "    \n",
    "    n = 0\n",
    "    label_val = pd.read_json(config['label_val'], lines = True, nrows = config['n_img_val'])\n",
    "    img_val_id = list(label_val['id'].values)\n",
    "    img_val_list = [config['img_val'] + r'\\\\' + str(i).zfill(5) + '.png' for i in img_val_id]\n",
    "    for img_path in img_val_list:\n",
    "        if n == 0:\n",
    "            img_val = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
    "            print('Validation Image', str(n), 'loaded.')\n",
    "        else:\n",
    "            img_val = torch.cat((img_val.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n",
    "        n += 1\n",
    "        if (n % 1000 == 0):\n",
    "            print('Validation Image', str(n), 'loaded.')\n",
    "    \n",
    "    text_val = list(label_val['text'].values)\n",
    "    print('Validation Text', str(config['n_img_val']), 'loaded.')\n",
    "    \n",
    "    labels_val = list(label_val['label'].values)\n",
    "    print('Validation Label', str(config['n_img_val']), 'loaded.')\n",
    "    \n",
    "    n = 0\n",
    "    label_test = pd.read_json(config['label_test'], lines = True, nrows = config['n_img_test'])\n",
    "    img_test_id = list(label_test['id'].values)\n",
    "    img_test_list = [config['img_test'] + r'\\\\' + str(i).zfill(5) + '.png' for i in img_test_id]\n",
    "    for img_path in img_test_list:\n",
    "        if n == 0:\n",
    "            img_test = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
    "            print('Test Image', str(n), 'loaded.')\n",
    "        else:\n",
    "            img_test = torch.cat((img_test.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n",
    "        n += 1\n",
    "        if (n % 1000 == 0):\n",
    "            print('Test Image', str(n), 'loaded.')\n",
    "    \n",
    "    text_test = list(label_test['text'].values)\n",
    "    print('Test Text', str(config['n_img_test']), 'loaded.')\n",
    "    \n",
    "    labels_test = list(label_test['label'].values)\n",
    "    print('Test Label', str(config['n_img_test']), 'loaded.')\n",
    "    \n",
    "    return img_train, text_train, labels_train, img_val, text_val, labels_val, img_test, text_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1c3adee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memes_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image, text, label, tokenizer, max_length = 48):\n",
    "        #Declare variables\n",
    "        self.image = image\n",
    "        self.text = text\n",
    "        self.labels = torch.tensor(label)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        meme_text = self.text[index]\n",
    "        tokens = self.tokenizer.encode_plus(meme_text, add_special_tokens = True, return_tensors = 'pt', truncation = True, \n",
    "                                           max_length = self.max_length, padding = 'max_length', return_attention_mask = True)\n",
    "        \n",
    "        return {'image': self.image[index], 'input_ids': tokens.input_ids.flatten(), \n",
    "                'attention_mask': tokens.attention_mask.flatten(), 'labels': self.labels[index]}\n",
    "    \n",
    "class Memes_Data_Module(lp.LightningDataModule):\n",
    "    \n",
    "    def __init__(self, train_image, train_text, train_labels, \n",
    "                 val_image, val_text, val_labels, \n",
    "                 test_image = None, test_text = None, test_labels = None, \n",
    "                 batch_size = 32, max_length = 48, text_model = 'roberta-base'):\n",
    "        super().__init__()\n",
    "        self.train_img = train_image\n",
    "        self.train_text = train_text\n",
    "        self.train_labels = train_labels\n",
    "        self.val_img = val_image\n",
    "        self.val_text = val_text\n",
    "        self.val_labels = val_labels\n",
    "\n",
    "        if test_image == None:\n",
    "            self.test_img = val_image\n",
    "            self.test_text = val_text\n",
    "            self.test_labels = val_labels\n",
    "        else:\n",
    "            self.test_img = test_image\n",
    "            self.test_text = test_text\n",
    "            self.test_labels = test_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(text_model)\n",
    "        \n",
    "    def setup(self, stage = None):\n",
    "        self.train_ds = Memes_Dataset(self.train_img, self.train_text, self.train_labels, \n",
    "                                      self.tokenizer, max_length = self.max_length)\n",
    "        self.val_ds = Memes_Dataset(self.val_img, self.val_text, self.val_labels, \n",
    "                                    self.tokenizer, max_length = self.max_length)\n",
    "        self.test_ds = Memes_Dataset(self.test_img, self.test_text, self.test_labels,\n",
    "                                    self.tokenizer, max_length = self.max_length)\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size = self.batch_size, shuffle = True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_ds, batch_size = self.batch_size, shuffle = False)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_ds, batch_size = self.batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8c243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVT_Fairface(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(config['model_name'])\n",
    "        self.model = CvtForImageClassification.from_pretrained(config['model_name']).to(device)\n",
    "        self.new_classifier = nn.Linear(384, self.config['n_labels']).to(device)\n",
    "        torch.nn.init.xavier_uniform_(self.new_classifier.weight)\n",
    "        self.model.classifier = self.new_classifier\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.training_auroc = []\n",
    "        self.training_acc = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_auroc = []\n",
    "        self.validation_acc = []\n",
    "        self.test_step_outputs = []\n",
    "        self.test_auroc = []\n",
    "        self.test_acc = []\n",
    "        self.tloss = []\n",
    "        self.tauroc = []\n",
    "        self.tacc = []\n",
    "        self.vloss = []\n",
    "        self.vauroc = []\n",
    "        self.vacc = []\n",
    "           \n",
    "    def forward(self, x, labels = None):\n",
    "        features = x.to(self.config['device'])\n",
    "        out = self.model(features)\n",
    "        return out.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.training_auroc.append(t_auroc)\n",
    "        self.training_acc.append(t_acc)\n",
    "        self.log(\"Training Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.training_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.training_acc).mean()\n",
    "        self.tloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.tauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.tacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.training_step_outputs.clear()\n",
    "        self.training_auroc.clear()\n",
    "        self.training_acc.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        v_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        v_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.validation_auroc.append(v_auroc)\n",
    "        self.validation_acc.append(v_acc)\n",
    "        self.log(\"Validation Accuracy\", v_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.validation_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.validation_acc).mean()\n",
    "        self.vloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.vauroc.append(float(epoch_auroc.detach().cpu().numpy()))\n",
    "        self.vacc.append(float(epoch_acc.detach().cpu().numpy()))\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_auroc.clear()\n",
    "        self.validation_acc.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.test_step_outputs.append(loss)\n",
    "        self.test_auroc.append(t_auroc)\n",
    "        self.test_acc.append(t_acc)\n",
    "        self.log(\"Test Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        x, y = batch\n",
    "        x = x.type(torch.cuda.FloatTensor)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(config['device'])\n",
    "        out = self.forward(x)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e51f546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Roberta_Pol(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = AutoModel.from_pretrained(config['model_name'], return_dict = True)\n",
    "        self.classifier = nn.Linear(self.model.config.hidden_size, self.config['n_labels'])\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.tloss = []\n",
    "        self.vloss = []\n",
    "           \n",
    "    def forward(self, input_ids, attention_mask, labels = None):\n",
    "        out = self.model(input_ids = input_ids, attention_mask = attention_mask)\n",
    "        out = torch.mean(out.last_hidden_state, 1)\n",
    "        # final logits\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.log(\"Training Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        self.tloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.training_step_outputs.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.log(\"Validation Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        self.vloss.append(float(epoch_mean.detach().cpu().numpy()))\n",
    "        self.validation_step_outputs.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        self.log(\"Test Loss\", loss, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        x = batch['input_ids']\n",
    "        y = batch['labels'].squeeze(1)\n",
    "        attn_mask = batch['attention_mask']\n",
    "        out = self.forward(x, attn_mask)\n",
    "        y = y.to(config['device'])\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bde8488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVT_Roberta(lp.LightningModule):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.cvt = torch.load(config['vmodel_path'])\n",
    "        self.roberta = torch.load(config['tmodel_path'])\n",
    "        self.layernorm_1 = nn.LayerNorm(self.config['hidden_size'])\n",
    "        self.layernorm_2 = nn.LayerNorm(self.config['hidden_size'])\n",
    "        self.batchnorm_1 = nn.BatchNorm1d(self.config['hidden_size'])\n",
    "        self.batchnorm_2 = nn.BatchNorm1d(self.config['hidden_size'])\n",
    "        self.linear_cvt = nn.Linear(384, self.config['hidden_size'])\n",
    "        self.linear_roberta = nn.Linear(self.roberta.model.config.hidden_size, self.config['hidden_size'])\n",
    "        self.classifier = nn.Sequential(nn.Linear(2 * self.config['hidden_size'], 2 * self.config['hidden_size']),\n",
    "                                       nn.ReLU(),\n",
    "                                       nn.Dropout(config['dropout']),\n",
    "                                        nn.LayerNorm(2 * self.config['hidden_size']),\n",
    "                                        nn.BatchNorm1d(2 * self.config['hidden_size']),\n",
    "                                       nn.Linear(2 * self.config['hidden_size'], self.config['n_labels']))\n",
    "        self.cvt.model.classifier = self.linear_cvt\n",
    "        self.roberta.classifier = self.linear_roberta\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.training_step_outputs = []\n",
    "        self.training_auroc = []\n",
    "        self.training_acc = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.validation_auroc = []\n",
    "        self.validation_acc = []\n",
    "        self.test_step_outputs = []\n",
    "        self.test_auroc = []\n",
    "        self.test_acc = []\n",
    "        self.tloss = []\n",
    "        self.tauroc = []\n",
    "        self.tacc = []\n",
    "        self.vloss = []\n",
    "        self.vauroc = []\n",
    "        self.vacc = []\n",
    "        \n",
    "    def forward(self, img, text, attn_mask, labels = None):\n",
    "        img = torch.squeeze(img)\n",
    "        v_out = self.batchnorm_1(self.layernorm_1(self.cvt(img)))\n",
    "        t_out = self.batchnorm_2(self.layernorm_2(self.roberta(text, attn_mask)))\n",
    "        out = torch.cat((v_out, t_out), dim = 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.training_step_outputs.append(loss)\n",
    "        self.training_auroc.append(t_auroc)\n",
    "        self.training_acc.append(t_acc)\n",
    "        self.log(\"Training Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.training_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.training_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.training_acc).mean()\n",
    "        self.tloss.append(round(float(epoch_mean.detach().cpu().numpy()), 4))\n",
    "        self.tauroc.append(round(float(epoch_auroc.detach().cpu().numpy()), 4))\n",
    "        self.tacc.append(round(float(epoch_acc.detach().cpu().numpy()), 4))\n",
    "        self.training_step_outputs.clear()\n",
    "        self.training_auroc.clear()\n",
    "        self.training_acc.clear()\n",
    "    \n",
    "    def validation_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        v_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        v_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.validation_step_outputs.append(loss)\n",
    "        self.validation_auroc.append(v_auroc)\n",
    "        self.validation_acc.append(v_acc)\n",
    "        self.log(\"Validation Accuracy\", v_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        epoch_mean = torch.stack(self.validation_step_outputs).mean()\n",
    "        epoch_auroc = torch.stack(self.validation_auroc).mean()\n",
    "        epoch_acc = torch.stack(self.validation_acc).mean()\n",
    "        self.vloss.append(round(float(epoch_mean.detach().cpu().numpy()), 4))\n",
    "        self.vauroc.append(round(float(epoch_auroc.detach().cpu().numpy()), 4))\n",
    "        self.vacc.append(round(float(epoch_acc.detach().cpu().numpy()), 4))\n",
    "        self.validation_step_outputs.clear()\n",
    "        self.validation_auroc.clear()\n",
    "        self.validation_acc.clear()\n",
    "    \n",
    "    def test_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        pred = self.softmax(out)\n",
    "        t_auroc = auroc(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        t_acc = accuracy(pred, y, task = 'multiclass', num_classes = self.config['n_labels'])\n",
    "        self.test_step_outputs.append(loss)\n",
    "        self.test_auroc.append(t_auroc)\n",
    "        self.test_acc.append(t_acc)\n",
    "        self.log(\"Test Accuracy\", t_acc, prog_bar = True, logger = True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_index):\n",
    "        loss, out, y = self._common_step(batch, batch_index)\n",
    "        return loss\n",
    "    \n",
    "    def _common_step(self, batch, batch_index):\n",
    "        img = batch['image']\n",
    "        text = batch['input_ids']\n",
    "        attn_mask = batch['attention_mask']\n",
    "        y = batch['labels']\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(config['device'])\n",
    "        img = img.type(torch.cuda.FloatTensor)\n",
    "        out = self.forward(img, text, attn_mask)\n",
    "        loss = self.loss(out, y)\n",
    "        return loss, out, y\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr = self.config['lr'], weight_decay = config['w_decay'])\n",
    "        return [optimizer]\n",
    "    \n",
    "    def plot_loss(self):\n",
    "        self.vloss.pop()\n",
    "        plt.plot(self.tloss, label = 'Training')\n",
    "        plt.plot(self.vloss, label = 'Validation')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_auroc(self):\n",
    "        self.vauroc.pop()\n",
    "        plt.plot(self.tauroc, label = 'Training')\n",
    "        plt.plot(self.vauroc, label = 'Validation')\n",
    "        print('Training AUROC')\n",
    "        print(self.tauroc)\n",
    "        print('Validation AUROC')\n",
    "        print(self.vauroc)\n",
    "        plt.title('AUROC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('AUROC')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_accuracy(self):\n",
    "        self.vacc.pop()\n",
    "        plt.plot(self.tacc, label = 'Training')\n",
    "        plt.plot(self.vacc, label = 'Validation')\n",
    "        print('Training Accuracy')\n",
    "        print(self.tacc)\n",
    "        print('Validation Accuracy')\n",
    "        print(self.vacc)\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ef1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath = config['ckpt_path'], \n",
    "        filename = \"Finetuned_Hateful_CKPT\",\n",
    "        every_n_epochs = config['val_every'],\n",
    "        save_top_k = 1,\n",
    "        monitor = 'Validation Accuracy',\n",
    "        mode = 'max'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datamodule\n",
    "\n",
    "if config['reload'] == True:\n",
    "    memes = Load_Memes(config)\n",
    "    memes_data_module = Memes_Data_Module(*memes, batch_size = config['batch_size'], text_model = config['tmodel_name'])\n",
    "else:\n",
    "    train_image = torch.load(config['img_train_rl'])\n",
    "    val_image = torch.load(config['img_val_rl'])\n",
    "    test_image = torch.load(config['img_test_rl'])\n",
    "    with open(config['label_train_rl'], 'rb') as f:\n",
    "        train_labels  = pickle.load(f)\n",
    "    with open(config['label_val_rl'], 'rb') as f:\n",
    "        val_labels = pickle.load(f)\n",
    "    with open(config['label_test_rl'], 'rb') as f:\n",
    "        test_labels = pickle.load(f)\n",
    "    with open(config['text_train_rl'], 'rb') as f:\n",
    "        train_text  = pickle.load(f)\n",
    "    with open(config['text_val_rl'], 'rb') as f:\n",
    "        val_text = pickle.load(f)\n",
    "    with open(config['text_test_rl'], 'rb') as f:\n",
    "        test_text = pickle.load(f)\n",
    "    memes_data_module = Memes_Data_Module(train_image, train_text, train_labels, val_image, val_text, val_labels,\n",
    "                                          test_image, test_text, test_labels,\n",
    "                                          batch_size = config['batch_size'], text_model = config['tmodel_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "409e5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = CVT_Roberta(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer and fit\n",
    "trainer = lp.Trainer(max_epochs = config['n_epochs'], devices = 1, accelerator = \"gpu\", num_sanity_val_steps = 0,\n",
    "                    callbacks = [checkpoint_callback], default_root_dir = config['ckpt_path'],\n",
    "                    check_val_every_n_epoch = config['val_every'])\n",
    "trainer.fit(model, memes_data_module)\n",
    "trainer.validate(model, memes_data_module)\n",
    "trainer.test(model, memes_data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5114b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_auroc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd708dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc167a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVT_Roberta(\n",
       "  (cvt): CVT_Fairface(\n",
       "    (model): CvtForImageClassification(\n",
       "      (cvt): CvtModel(\n",
       "        (encoder): CvtEncoder(\n",
       "          (stages): ModuleList(\n",
       "            (0): CvtStage(\n",
       "              (embedding): CvtEmbeddings(\n",
       "                (convolution_embeddings): CvtConvEmbeddings(\n",
       "                  (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
       "                  (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layers): Sequential(\n",
       "                (0): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                          (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (projection_key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (projection_value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=64, out_features=256, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=256, out_features=64, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): CvtStage(\n",
       "              (embedding): CvtEmbeddings(\n",
       "                (convolution_embeddings): CvtConvEmbeddings(\n",
       "                  (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                  (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layers): Sequential(\n",
       "                (0): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (2): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (3): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                          (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): CvtStage(\n",
       "              (embedding): CvtEmbeddings(\n",
       "                (convolution_embeddings): CvtConvEmbeddings(\n",
       "                  (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "                  (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (layers): Sequential(\n",
       "                (0): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (1): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (2): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (3): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (4): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (5): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (6): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (7): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (8): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (9): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (10): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (11): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (12): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (13): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (14): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "                (15): CvtLayer(\n",
       "                  (attention): CvtAttention(\n",
       "                    (attention): CvtSelfAttention(\n",
       "                      (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                        (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                          (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                          (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                        )\n",
       "                        (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                      )\n",
       "                      (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                    (output): CvtSelfOutput(\n",
       "                      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                      (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (intermediate): CvtIntermediate(\n",
       "                    (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                    (activation): GELU(approximate='none')\n",
       "                  )\n",
       "                  (output): CvtOutput(\n",
       "                    (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (drop_path): CvtDropPath(p=0.013333333656191826)\n",
       "                  (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                  (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (classifier): Linear(in_features=384, out_features=128, bias=True)\n",
       "    )\n",
       "    (new_classifier): Linear(in_features=384, out_features=14, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (loss): CrossEntropyLoss()\n",
       "  )\n",
       "  (roberta): Roberta_Pol(\n",
       "    (model): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (classifier): Linear(in_features=768, out_features=128, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "    (loss): MSELoss()\n",
       "  )\n",
       "  (layernorm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (layernorm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (batchnorm_1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm_2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear_cvt): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (linear_roberta): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.492, inplace=False)\n",
       "    (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(r'C:\\Users\\rabby\\CS 7643 - Deep Learning\\Project\\Unimodal Models\\Hateful_6465_6695\\Finetuned_Hateful_CKPT.ckpt')['state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "del state_dict\n",
    "model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d99ef77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\models\\convnext\\feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rabby\\AppData\\Local\\Temp\\ipykernel_19428\\3864625937.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_train = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
      "C:\\Users\\rabby\\AppData\\Local\\Temp\\ipykernel_19428\\3864625937.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_val = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
      "C:\\Users\\rabby\\AppData\\Local\\Temp\\ipykernel_19428\\3864625937.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_test = torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0])\n",
      "C:\\Users\\rabby\\AppData\\Local\\Temp\\ipykernel_19428\\3864625937.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img_test = torch.cat((img_test.view(n, 3, 224, 224), torch.tensor(extractor(torchvision.io.read_image(img_path), return_tensors=\"pt\")['pixel_values'][0]).view(1, 3, 224, 224)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Image 0 loaded.\n",
      "Training Text 1 loaded.\n",
      "Training Label 1 loaded.\n",
      "Validation Image 0 loaded.\n",
      "Validation Text 1 loaded.\n",
      "Validation Label 1 loaded.\n",
      "Test Image 0 loaded.\n",
      "Test Image 1000 loaded.\n",
      "Test Text 1000 loaded.\n",
      "Test Label 1000 loaded.\n"
     ]
    }
   ],
   "source": [
    "memes = Load_Memes(config)\n",
    "memes_data_module = Memes_Data_Module(*memes, batch_size = config['batch_size'], text_model = config['tmodel_name'])\n",
    "memes_data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cac21a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "auc = []\n",
    "for i in range(100):\n",
    "    acc_list = []\n",
    "    auroc_list = []\n",
    "    softmax = nn.Softmax(dim = 1)\n",
    "    with torch.no_grad():\n",
    "        for i, j in enumerate(memes_data_module.test_dataloader()):\n",
    "            j['image'] = j['image'].to(config['device'])\n",
    "            j['input_ids'] = j['input_ids'].to(config['device'])\n",
    "            j['attention_mask'] = j['attention_mask'].to(config['device'])\n",
    "            j['labels'] = j['labels'].to(config['device'])\n",
    "            pred = softmax(model(j['image'], j['input_ids'], j['attention_mask']))\n",
    "            temp_acc = accuracy(pred, j['labels'], task = 'multiclass', num_classes = config['n_labels'])\n",
    "            temp_auroc = auroc(pred, j['labels'], task = 'multiclass', num_classes = config['n_labels'])\n",
    "            acc_list.append(temp_acc.item())\n",
    "            auroc_list.append(temp_auroc.item())\n",
    "    acc_list = np.array(acc_list)\n",
    "    acc_mean = acc_list.mean().round(4)\n",
    "    acc.append(acc_mean)\n",
    "    auc_list = np.array(auroc_list)\n",
    "    auc_mean = auc_list.mean().round(4)\n",
    "    auc.append(auc_mean)\n",
    "acc = np.array(acc)\n",
    "auc = np.array(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94379392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6289, 0.6162, 0.6201, 0.6123, 0.6396, 0.6289, 0.6309, 0.6318,\n",
       "       0.6289, 0.6318, 0.6504, 0.6348, 0.6367, 0.6348, 0.6289, 0.6436,\n",
       "       0.6465, 0.6318, 0.6279, 0.6309, 0.6338, 0.6318, 0.6387, 0.6523,\n",
       "       0.624 , 0.6396, 0.6309, 0.6133, 0.6328, 0.6406, 0.6445, 0.6279,\n",
       "       0.6396, 0.6406, 0.6279, 0.624 , 0.6504, 0.6289, 0.6279, 0.625 ,\n",
       "       0.6299, 0.6279, 0.6406, 0.626 , 0.6338, 0.6191, 0.6396, 0.6289,\n",
       "       0.6152, 0.6484, 0.6387, 0.6133, 0.6201, 0.623 , 0.625 , 0.6318,\n",
       "       0.626 , 0.623 , 0.6221, 0.627 , 0.6436, 0.623 , 0.6338, 0.6211,\n",
       "       0.6328, 0.6357, 0.6406, 0.6377, 0.627 , 0.6348, 0.6357, 0.627 ,\n",
       "       0.6396, 0.6289, 0.6299, 0.6289, 0.6338, 0.6367, 0.6455, 0.6416,\n",
       "       0.6357, 0.6523, 0.6514, 0.625 , 0.627 , 0.626 , 0.6357, 0.6309,\n",
       "       0.6377, 0.6318, 0.6123, 0.6338, 0.626 , 0.6348, 0.6465, 0.6377,\n",
       "       0.627 , 0.6455, 0.6338, 0.6309])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1938afe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Mean:\n",
      "0.6323\n",
      "Accuracy Std Dev:\n",
      "0.0089\n",
      "-----------------\n",
      "AUROC Mean:\n",
      "0.716\n",
      "AUROC Std Dev:\n",
      "0.0074\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Mean:')\n",
    "print(acc.mean().round(4))\n",
    "print('Accuracy Std Dev:')\n",
    "print(acc.std().round(4))\n",
    "print('-----------------')\n",
    "print('AUROC Mean:')\n",
    "print(auc.mean().round(4))\n",
    "print('AUROC Std Dev:')\n",
    "print(auc.std().round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
